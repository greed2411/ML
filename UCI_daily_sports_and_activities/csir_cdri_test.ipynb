{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSIR CDRI Internship Test. - Jaivarsan. B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been done according to the **research** paper,\n",
    "\n",
    "K. Altun, B. Barshan, and O. Tunçel,\n",
    "`Comparative study on classifying human activities with miniature inertial and magnetic sensors`,\n",
    "Pattern Recognition, 43(10):3605-3620, October 2010.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where they take the input segment, that's a 5 second window of a patient performing an activity, which has 125 observations ( 5 x 25Hz ) with 45 features, because of 9 axes of each sensor unit on torso, left hand, right hand, left leg, right leg. They convert the 125x45 into a handcrafted meaningful 1170x1 matrix.\n",
    "\n",
    "The 1170 features represents, \n",
    "    * 225 features ( min, max, mean, skewness, kurtosis of all 9 axes of all 5 units, thus 5x9x5 ) i.e., first_step\n",
    "    * 225 features which represent the maximum 5 peaks of the DFT applied on each of the 9 axes of all the 5 units i.e.,\n",
    "    second_step\n",
    "    * 225 features which represent the corresponding frequency of the 5 peaks of the DFT over the time series i.e.,\n",
    "    third_step.\n",
    "    * 495 features which represent the autocorrelation of the series, 11 hand picked values from the 125 \n",
    "    autocorrelation values for each axes, thus 11 x 9 x 5 = 495 i.e, fourth_step.\n",
    "    \n",
    "Adding them all 225 + 225 + 225 + 495 = 1170, for each segment, i.e., each text file.\n",
    "\n",
    "Then these values are normalized in the range [0,1], and stored along with the patient ID and activity ID for that segment / text file.\n",
    "\n",
    "The test I performed includes two parts, one with 9120 x 1170 matrix, and another with 9120 x 30 matrix, I did PCA over the initial matrix, unfortunately, the PCA didn't live up to my expectations, so I'm producing both results.\n",
    "\n",
    "I request you to consider my 9120 x 1170 dataset into consideration, and its results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>5.4217</td>\n",
       "      <td>-0.009461</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.003424</td>\n",
       "      <td>-0.78712</td>\n",
       "      <td>-0.069654</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.70097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036453</td>\n",
       "      <td>-2.8071</td>\n",
       "      <td>-9.0812</td>\n",
       "      <td>2.6220</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>0.74017</td>\n",
       "      <td>0.30053</td>\n",
       "      <td>-0.057730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0202</td>\n",
       "      <td>5.3843</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>-0.78717</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.71829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034005</td>\n",
       "      <td>-2.8146</td>\n",
       "      <td>-9.0737</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.73937</td>\n",
       "      <td>0.30183</td>\n",
       "      <td>-0.057514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1604</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>5.3622</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.78664</td>\n",
       "      <td>-0.068277</td>\n",
       "      <td>0.15879</td>\n",
       "      <td>0.69849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036489</td>\n",
       "      <td>-2.8221</td>\n",
       "      <td>-9.0886</td>\n",
       "      <td>2.6366</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.007918</td>\n",
       "      <td>0.73955</td>\n",
       "      <td>0.30052</td>\n",
       "      <td>-0.057219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1603</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>5.3770</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>-0.78529</td>\n",
       "      <td>-0.069849</td>\n",
       "      <td>0.15912</td>\n",
       "      <td>0.72799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036151</td>\n",
       "      <td>-2.8071</td>\n",
       "      <td>-9.0811</td>\n",
       "      <td>2.6070</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.74029</td>\n",
       "      <td>0.30184</td>\n",
       "      <td>-0.057750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.1605</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>5.3473</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.78742</td>\n",
       "      <td>-0.068796</td>\n",
       "      <td>0.15916</td>\n",
       "      <td>0.71572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033807</td>\n",
       "      <td>-2.8146</td>\n",
       "      <td>-9.0737</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.73845</td>\n",
       "      <td>0.30090</td>\n",
       "      <td>-0.057527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2         3         4         5        6         7   \\\n",
       "0  8.1305  1.0349  5.4217 -0.009461  0.001915 -0.003424 -0.78712 -0.069654   \n",
       "1  8.1305  1.0202  5.3843 -0.009368  0.023485  0.001953 -0.78717 -0.068275   \n",
       "2  8.1604  1.0201  5.3622  0.015046  0.014330  0.000204 -0.78664 -0.068277   \n",
       "3  8.1603  1.0052  5.3770  0.006892  0.018045  0.005649 -0.78529 -0.069849   \n",
       "4  8.1605  1.0275  5.3473  0.008811  0.030433 -0.005346 -0.78742 -0.068796   \n",
       "\n",
       "        8        9     ...           35      36      37      38        39  \\\n",
       "0  0.15730  0.70097    ...    -0.036453 -2.8071 -9.0812  2.6220 -0.000232   \n",
       "1  0.15890  0.71829    ...    -0.034005 -2.8146 -9.0737  2.6218 -0.014784   \n",
       "2  0.15879  0.69849    ...    -0.036489 -2.8221 -9.0886  2.6366 -0.012770   \n",
       "3  0.15912  0.72799    ...    -0.036151 -2.8071 -9.0811  2.6070 -0.005725   \n",
       "4  0.15916  0.71572    ...    -0.033807 -2.8146 -9.0737  2.6218 -0.003929   \n",
       "\n",
       "         40        41       42       43        44  \n",
       "0 -0.012092 -0.004457  0.74017  0.30053 -0.057730  \n",
       "1 -0.016477  0.002789  0.73937  0.30183 -0.057514  \n",
       "2  0.005717 -0.007918  0.73955  0.30052 -0.057219  \n",
       "3  0.009620  0.006555  0.74029  0.30184 -0.057750  \n",
       "4 -0.008371  0.002816  0.73845  0.30090 -0.057527  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('s01.txt', header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we need to convert these 125 x 45 columns into 1170 x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>125.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>5.606846</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>-0.003726</td>\n",
       "      <td>-0.790726</td>\n",
       "      <td>-0.068490</td>\n",
       "      <td>0.135897</td>\n",
       "      <td>0.679134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035894</td>\n",
       "      <td>-2.814833</td>\n",
       "      <td>-9.085131</td>\n",
       "      <td>2.618207</td>\n",
       "      <td>-0.005036</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>0.739615</td>\n",
       "      <td>0.301314</td>\n",
       "      <td>-0.057119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.119981</td>\n",
       "      <td>0.046987</td>\n",
       "      <td>0.181035</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.036279</td>\n",
       "      <td>0.007920</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.019892</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>0.018793</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.682300</td>\n",
       "      <td>0.997440</td>\n",
       "      <td>5.316900</td>\n",
       "      <td>-0.039399</td>\n",
       "      <td>-0.080639</td>\n",
       "      <td>-0.030754</td>\n",
       "      <td>-0.795540</td>\n",
       "      <td>-0.071582</td>\n",
       "      <td>0.109560</td>\n",
       "      <td>0.585420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>-2.867500</td>\n",
       "      <td>-9.112400</td>\n",
       "      <td>2.571100</td>\n",
       "      <td>-0.024685</td>\n",
       "      <td>-0.019207</td>\n",
       "      <td>-0.021531</td>\n",
       "      <td>0.737520</td>\n",
       "      <td>0.299680</td>\n",
       "      <td>-0.059241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.876300</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>5.436400</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>-0.008867</td>\n",
       "      <td>-0.793210</td>\n",
       "      <td>-0.069849</td>\n",
       "      <td>0.119820</td>\n",
       "      <td>0.649210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036599</td>\n",
       "      <td>-2.822500</td>\n",
       "      <td>-9.089400</td>\n",
       "      <td>2.608400</td>\n",
       "      <td>-0.009489</td>\n",
       "      <td>-0.003025</td>\n",
       "      <td>-0.007918</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.300710</td>\n",
       "      <td>-0.057598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.958700</td>\n",
       "      <td>1.080700</td>\n",
       "      <td>5.608100</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.023588</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.791610</td>\n",
       "      <td>-0.068773</td>\n",
       "      <td>0.135040</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035765</td>\n",
       "      <td>-2.815000</td>\n",
       "      <td>-9.088600</td>\n",
       "      <td>2.622000</td>\n",
       "      <td>-0.005644</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>0.739550</td>\n",
       "      <td>0.301320</td>\n",
       "      <td>-0.057208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.108200</td>\n",
       "      <td>1.124000</td>\n",
       "      <td>5.749300</td>\n",
       "      <td>0.014090</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>-0.787430</td>\n",
       "      <td>-0.067195</td>\n",
       "      <td>0.155050</td>\n",
       "      <td>0.708470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035240</td>\n",
       "      <td>-2.807500</td>\n",
       "      <td>-9.074500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.740240</td>\n",
       "      <td>0.301830</td>\n",
       "      <td>-0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.160500</td>\n",
       "      <td>1.183200</td>\n",
       "      <td>6.181400</td>\n",
       "      <td>0.045403</td>\n",
       "      <td>0.214760</td>\n",
       "      <td>0.015614</td>\n",
       "      <td>-0.785290</td>\n",
       "      <td>-0.064353</td>\n",
       "      <td>0.159160</td>\n",
       "      <td>0.759300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033109</td>\n",
       "      <td>-2.747600</td>\n",
       "      <td>-9.044500</td>\n",
       "      <td>2.669600</td>\n",
       "      <td>0.015853</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.742380</td>\n",
       "      <td>0.303420</td>\n",
       "      <td>-0.054963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  125.000000  125.000000  125.000000  125.000000  125.000000  125.000000   \n",
       "mean     7.975714    1.083150    5.606846    0.004897    0.026123   -0.003726   \n",
       "std      0.119981    0.046987    0.181035    0.015592    0.036279    0.007920   \n",
       "min      7.682300    0.997440    5.316900   -0.039399   -0.080639   -0.030754   \n",
       "25%      7.876300    1.035000    5.436400   -0.005710    0.010725   -0.008867   \n",
       "50%      7.958700    1.080700    5.608100    0.005122    0.023588   -0.003457   \n",
       "75%      8.108200    1.124000    5.749300    0.014090    0.043022    0.001953   \n",
       "max      8.160500    1.183200    6.181400    0.045403    0.214760    0.015614   \n",
       "\n",
       "               6           7           8           9      ...              35  \\\n",
       "count  125.000000  125.000000  125.000000  125.000000     ...      125.000000   \n",
       "mean    -0.790726   -0.068490    0.135897    0.679134     ...       -0.035894   \n",
       "std      0.002870    0.001751    0.015907    0.039324     ...        0.001074   \n",
       "min     -0.795540   -0.071582    0.109560    0.585420     ...       -0.039347   \n",
       "25%     -0.793210   -0.069849    0.119820    0.649210     ...       -0.036599   \n",
       "50%     -0.791610   -0.068773    0.135040    0.688700     ...       -0.035765   \n",
       "75%     -0.787430   -0.067195    0.155050    0.708470     ...       -0.035240   \n",
       "max     -0.785290   -0.064353    0.159160    0.759300     ...       -0.033109   \n",
       "\n",
       "               36          37          38          39          40          41  \\\n",
       "count  125.000000  125.000000  125.000000  125.000000  125.000000  125.000000   \n",
       "mean    -2.814833   -9.085131    2.618207   -0.005036    0.002166   -0.003155   \n",
       "std      0.019892    0.013178    0.018793    0.007633    0.007310    0.007074   \n",
       "min     -2.867500   -9.112400    2.571100   -0.024685   -0.019207   -0.021531   \n",
       "25%     -2.822500   -9.089400    2.608400   -0.009489   -0.003025   -0.007918   \n",
       "50%     -2.815000   -9.088600    2.622000   -0.005644    0.001586   -0.002558   \n",
       "75%     -2.807500   -9.074500    2.625000   -0.000232    0.007598    0.001253   \n",
       "max     -2.747600   -9.044500    2.669600    0.015853    0.020288    0.013777   \n",
       "\n",
       "               42          43          44  \n",
       "count  125.000000  125.000000  125.000000  \n",
       "mean     0.739615    0.301314   -0.057119  \n",
       "std      0.000850    0.000792    0.000823  \n",
       "min      0.737520    0.299680   -0.059241  \n",
       "25%      0.739000    0.300710   -0.057598  \n",
       "50%      0.739550    0.301320   -0.057208  \n",
       "75%      0.740240    0.301830   -0.056500  \n",
       "max      0.742380    0.303420   -0.054963  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating min, max, mean, skew and curtosis for all 45 axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_step = list(df.min())+list(df.max())+list(df.mean())+list(df.skew())+list(df.kurtosis())\n",
    "len(first_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating DFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0349</td>\n",
       "      <td>5.4217</td>\n",
       "      <td>-0.009461</td>\n",
       "      <td>0.001915</td>\n",
       "      <td>-0.003424</td>\n",
       "      <td>-0.78712</td>\n",
       "      <td>-0.069654</td>\n",
       "      <td>0.15730</td>\n",
       "      <td>0.70097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036453</td>\n",
       "      <td>-2.8071</td>\n",
       "      <td>-9.0812</td>\n",
       "      <td>2.6220</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.004457</td>\n",
       "      <td>0.74017</td>\n",
       "      <td>0.30053</td>\n",
       "      <td>-0.057730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.1305</td>\n",
       "      <td>1.0202</td>\n",
       "      <td>5.3843</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>-0.78717</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.71829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034005</td>\n",
       "      <td>-2.8146</td>\n",
       "      <td>-9.0737</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.014784</td>\n",
       "      <td>-0.016477</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.73937</td>\n",
       "      <td>0.30183</td>\n",
       "      <td>-0.057514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1604</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>5.3622</td>\n",
       "      <td>0.015046</td>\n",
       "      <td>0.014330</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-0.78664</td>\n",
       "      <td>-0.068277</td>\n",
       "      <td>0.15879</td>\n",
       "      <td>0.69849</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036489</td>\n",
       "      <td>-2.8221</td>\n",
       "      <td>-9.0886</td>\n",
       "      <td>2.6366</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>0.005717</td>\n",
       "      <td>-0.007918</td>\n",
       "      <td>0.73955</td>\n",
       "      <td>0.30052</td>\n",
       "      <td>-0.057219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.1603</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>5.3770</td>\n",
       "      <td>0.006892</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.005649</td>\n",
       "      <td>-0.78529</td>\n",
       "      <td>-0.069849</td>\n",
       "      <td>0.15912</td>\n",
       "      <td>0.72799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036151</td>\n",
       "      <td>-2.8071</td>\n",
       "      <td>-9.0811</td>\n",
       "      <td>2.6070</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>0.009620</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.74029</td>\n",
       "      <td>0.30184</td>\n",
       "      <td>-0.057750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.1605</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>5.3473</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.030433</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>-0.78742</td>\n",
       "      <td>-0.068796</td>\n",
       "      <td>0.15916</td>\n",
       "      <td>0.71572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033807</td>\n",
       "      <td>-2.8146</td>\n",
       "      <td>-9.0737</td>\n",
       "      <td>2.6218</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.73845</td>\n",
       "      <td>0.30090</td>\n",
       "      <td>-0.057527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2         3         4         5        6         7   \\\n",
       "0  8.1305  1.0349  5.4217 -0.009461  0.001915 -0.003424 -0.78712 -0.069654   \n",
       "1  8.1305  1.0202  5.3843 -0.009368  0.023485  0.001953 -0.78717 -0.068275   \n",
       "2  8.1604  1.0201  5.3622  0.015046  0.014330  0.000204 -0.78664 -0.068277   \n",
       "3  8.1603  1.0052  5.3770  0.006892  0.018045  0.005649 -0.78529 -0.069849   \n",
       "4  8.1605  1.0275  5.3473  0.008811  0.030433 -0.005346 -0.78742 -0.068796   \n",
       "\n",
       "        8        9     ...           35      36      37      38        39  \\\n",
       "0  0.15730  0.70097    ...    -0.036453 -2.8071 -9.0812  2.6220 -0.000232   \n",
       "1  0.15890  0.71829    ...    -0.034005 -2.8146 -9.0737  2.6218 -0.014784   \n",
       "2  0.15879  0.69849    ...    -0.036489 -2.8221 -9.0886  2.6366 -0.012770   \n",
       "3  0.15912  0.72799    ...    -0.036151 -2.8071 -9.0811  2.6070 -0.005725   \n",
       "4  0.15916  0.71572    ...    -0.033807 -2.8146 -9.0737  2.6218 -0.003929   \n",
       "\n",
       "         40        41       42       43        44  \n",
       "0 -0.012092 -0.004457  0.74017  0.30053 -0.057730  \n",
       "1 -0.016477  0.002789  0.73937  0.30183 -0.057514  \n",
       "2  0.005717 -0.007918  0.73955  0.30052 -0.057219  \n",
       "3  0.009620  0.006555  0.74029  0.30184 -0.057750  \n",
       "4 -0.008371  0.002816  0.73845  0.30090 -0.057527  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125, 45)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.as_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm gonna convert the 125 x 45 matrix as 45 vectors of the dimension 125 x 1, that is Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.1305  ,  8.1305  ,  8.1604  , ...,  7.9517  ,  7.9743  ,  7.9812  ],\n",
       "       [ 1.0349  ,  1.0202  ,  1.0201  , ...,  1.1466  ,  1.1542  ,  1.0945  ],\n",
       "       [ 5.4217  ,  5.3843  ,  5.3622  , ...,  5.6081  ,  5.5038  ,  5.6005  ],\n",
       "       ..., \n",
       "       [ 0.74017 ,  0.73937 ,  0.73955 , ...,  0.73945 ,  0.7403  ,\n",
       "         0.73897 ],\n",
       "       [ 0.30053 ,  0.30183 ,  0.30052 , ...,  0.30342 ,  0.30027 ,\n",
       "         0.30275 ],\n",
       "       [-0.05773 , -0.057514, -0.057219, ..., -0.056789, -0.056704,\n",
       "        -0.056262]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.as_matrix().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9.96964300e+02 +0.00000000e+00j,\n",
       "          6.82091976e+00 -6.84917855e+00j,\n",
       "         -1.53490535e+00 -3.24821215e-01j, ...,\n",
       "         -4.18487957e-01 +6.43827006e-01j,\n",
       "         -1.53490535e+00 +3.24821215e-01j,\n",
       "          6.82091976e+00 +6.84917855e+00j],\n",
       "       [  1.35393810e+02 +0.00000000e+00j,\n",
       "         -6.02662401e-01 +3.04781499e+00j,\n",
       "          1.88982223e-01 +1.18731082e+00j, ...,\n",
       "         -2.99035182e-01 -3.77556488e-01j,\n",
       "          1.88982223e-01 -1.18731082e+00j,\n",
       "         -6.02662401e-01 -3.04781499e+00j],\n",
       "       [  7.00855800e+02 +0.00000000e+00j,\n",
       "         -9.59384443e+00 +9.20132161e+00j,\n",
       "          1.98649365e+00 -2.11594225e-01j, ...,\n",
       "          1.35861527e+00 -7.82430548e-01j,\n",
       "          1.98649365e+00 +2.11594225e-01j,\n",
       "         -9.59384443e+00 -9.20132161e+00j],\n",
       "       ..., \n",
       "       [  9.24518400e+01 +0.00000000e+00j,\n",
       "          3.65364166e-03 +1.53477972e-02j,\n",
       "         -3.51854014e-03 +7.08006424e-03j, ...,\n",
       "          2.12567143e-03 -2.46017755e-03j,\n",
       "         -3.51854014e-03 -7.08006424e-03j,\n",
       "          3.65364166e-03 -1.53477972e-02j],\n",
       "       [  3.76642700e+01 +0.00000000e+00j,\n",
       "          1.14965487e-02 +8.04676898e-04j,\n",
       "         -4.18917786e-03 +6.86883491e-03j, ...,\n",
       "         -3.69368906e-04 -1.34295971e-02j,\n",
       "         -4.18917786e-03 -6.86883491e-03j,\n",
       "          1.14965487e-02 -8.04676898e-04j],\n",
       "       [ -7.13984600e+00 +0.00000000e+00j,\n",
       "          1.00967398e-02 -3.05730723e-04j,\n",
       "         -1.83111144e-02 -4.93063934e-03j, ...,\n",
       "         -1.86821090e-03 +7.22473510e-03j,\n",
       "         -1.83111144e-02 +4.93063934e-03j,\n",
       "          1.00967398e-02 +3.05730723e-04j]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_matrix = np.fft.fft(df.as_matrix().T)\n",
    "dft_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.96964300e+02+0.j        ,   6.82091976e+00-6.84917855j,\n",
       "         6.82091976e+00+6.84917855j,   6.87482726e-02-1.99417014j,\n",
       "         6.87482726e-02+1.99417014j])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft_matrix[0][np.absolute(dft_matrix)[0].argsort()[-5:][::-1]] # these are the five maximum values from 0th column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How? The process is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "abs_dft_matrix = np.absolute(dft_matrix) # taking the absolute value of the complex numbers, to find the maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 996.9643    ,    9.66623987,    9.66623987,    1.99535482,\n",
       "          1.99535482])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_dft_matrix[0][abs_dft_matrix[0].argsort()[-5:][::-1]] # these are the 5 maximum absolute values for the above cell values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1, 124,   5, 120])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions = abs_dft_matrix[0].argsort()[-5:][::-1] # these are the positions mentioned for the above mentioned cell values.\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2566370614359172"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If T is the total amount of time passed in your signal that you are taking the dft with\n",
    "# and k is the index\n",
    "# then the frequency at index k is\n",
    "# 2 pi k / T\n",
    "f_k = (2*math.pi)/5\n",
    "f_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    1.25663706,  155.82299562,    6.28318531,\n",
       "        150.79644737])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions*f_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_step =[]\n",
    "third_step = []\n",
    "for i in range(len(abs_dft_matrix)):\n",
    "    positions = abs_dft_matrix[i].argsort()[-5:][::-1]\n",
    "    second_step.append(list(abs_dft_matrix[i][positions]))\n",
    "    third_step.append(list(positions*f_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "second_step = [item for sublist in second_step for item in sublist] # flattening the lists.\n",
    "third_step = [item for sublist in third_step for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autocorrelation formula from pg 3/16 of the research paper](autocorrelation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorr_reqd = [0,4,9,14,19,24,29,34,39,44,49] # getting the required autocorr values as mentioned in the paper.\n",
    "len(autocorr_reqd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fourth_step = []\n",
    "autocorr_reqd = [0,4,9,14,19,24,29,34,39,44,49]\n",
    "\n",
    "for column in df.columns:\n",
    "    mean = df[column].mean()\n",
    "    for delta in range(len(df)):\n",
    "        if(delta in autocorr_reqd):\n",
    "            sum_of_products = 0\n",
    "            for i, row in enumerate(df[column], start = delta):\n",
    "                element_1 = row - mean\n",
    "                element_2 = df[column].iloc[len(df)-1-i] - mean\n",
    "                sum_of_products += element_1*element_2\n",
    "            rss = 1/(len(df)-delta)*sum_of_products \n",
    "            fourth_step.append(rss)\n",
    "\n",
    "len(fourth_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with feature engineering, combining all the efforts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1170"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_representation = first_step + second_step + third_step + fourth_step\n",
    "len(final_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.asarray(final_representation)\n",
    "normalized = (arr-min(arr))/(max(arr)-min(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01467101,  0.00883145,  0.01260472, ...,  0.00796014,\n",
       "        0.00796014,  0.00796014])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1170,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01467101],\n",
       "       [ 0.00883145],\n",
       "       [ 0.01260472],\n",
       "       ..., \n",
       "       [ 0.00796014],\n",
       "       [ 0.00796014],\n",
       "       [ 0.00796014]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess PCA requires all, the data, instead of just on vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# X = normalized\n",
    "# pca = PCA(n_components=30, svd_solver='full')\n",
    "# pca.fit(X.reshape(-1,1))\n",
    "\n",
    "# ValueError: n_components=30 must be between 0 and n_features=1 with svd_solver='full'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering all the input and labelling them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/greed/Windows8_OS/Me/Files/Projects/ML and DS/Daily_sports_and_activities'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(filename):\n",
    "    \"\"\"\n",
    "    A function which will take the text file name and preprocess using the techniques followed\n",
    "    in the above cells to reduce 125 x 45 into a 1170,1 and return it.\n",
    "    It also returns the patient identity and activity identity.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('{}'.format(filename), header=None)\n",
    "    \n",
    "    # first step\n",
    "    first_step = list(df.min())+list(df.max())+list(df.mean())+list(df.skew())+list(df.kurtosis())\n",
    "    \n",
    "    # second step and third step\n",
    "    f_k = (2*math.pi)/5\n",
    "    second_step =[]\n",
    "    third_step = []\n",
    "    for i in range(len(abs_dft_matrix)):\n",
    "        positions = abs_dft_matrix[i].argsort()[-5:][::-1]\n",
    "        second_step.append(list(abs_dft_matrix[i][positions]))\n",
    "        third_step.append(list(positions*f_k))\n",
    "    second_step = [item for sublist in second_step for item in sublist] # flattening the lists.\n",
    "    third_step = [item for sublist in third_step for item in sublist]\n",
    "    \n",
    "    # fourth step   \n",
    "    fourth_step = []\n",
    "    autocorr_reqd = [0,4,9,14,19,24,29,34,39,44,49]\n",
    "\n",
    "    for column in df.columns:\n",
    "        mean = df[column].mean()\n",
    "        for delta in range(len(df)):\n",
    "            if(delta in autocorr_reqd):\n",
    "                sum_of_products = 0\n",
    "                for i, row in enumerate(df[column], start = delta):\n",
    "                    element_1 = row - mean\n",
    "                    element_2 = df[column].iloc[len(df)-1-i] - mean\n",
    "                    sum_of_products += element_1*element_2\n",
    "                rss = 1/(len(df)-delta)*sum_of_products \n",
    "                fourth_step.append(rss)\n",
    "    \n",
    "    # finalizing\n",
    "    final_representation = first_step + second_step + third_step + fourth_step\n",
    "    arr = np.asarray(final_representation)\n",
    "    normalized = (arr-min(arr))/(max(arr)-min(arr))\n",
    "    \n",
    "\n",
    "    return normalized, patient, activity_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_values_list = []\n",
    "patient_label_list = []\n",
    "activity_label_list = []\n",
    "\n",
    "\n",
    "for activity_folder in name_of_activity:\n",
    "    \n",
    "    os.chdir('/media/greed/Windows8_OS/Me/Files/Projects/ML and DS/Daily_sports_and_activities/data')\n",
    "    # going inside each activity folder\n",
    "    os.chdir(activity_folder)\n",
    "    print(activity_folder)\n",
    "    patient_files = os.listdir()\n",
    "    \n",
    "    for patient in patient_files:\n",
    "        \n",
    "        # going into every patient folder\n",
    "        os.chdir(patient)\n",
    "        print(patient)\n",
    "        segment_files = os.listdir()\n",
    "        \n",
    "        # getting all the segment txt files inside the patient folder\n",
    "        print(segment_files)\n",
    "        \n",
    "        for filename in segment_files:\n",
    "            \n",
    "            # obtaining the 1170x1 vector, patient id, activity id from the text file.\n",
    "            print('Doing {}'.format(filename))\n",
    "            normalized, patient, activity_folder = preprocess(filename)\n",
    "            \n",
    "            normalized_values_list.append(list(normalized)) # a 2D list with 9120 lists insdie it, each has 1170 values.\n",
    "            patient_label_list.append(patient) # a 1D list with 9120 patient ids.\n",
    "            activity_label_list.append(activity_folder) # a 1D list iwth 9120 activity ids.\n",
    "        \n",
    "        os.chdir('/media/greed/Windows8_OS/Me/Files/Projects/ML and DS/Daily_sports_and_activities/data/{}'.format(activity_folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.014742296336893494,\n",
       " 0.0090230219313977081,\n",
       " 0.012502701438187162,\n",
       " 0.0079369476901982802,\n",
       " 0.0079449685812037901,\n",
       " 0.0079448410436208216,\n",
       " 0.0072731014676780436,\n",
       " 0.0078975708982297246,\n",
       " 0.0080660794929524986,\n",
       " 0.0082585389469204285]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_values_list[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(normalized_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1160</th>\n",
       "      <th>1161</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "       7         8         9       ...         1160      1161      1162  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1163      1164      1165      1166      1167      1168      1169  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960  0.007960  0.007960  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968  0.007968  0.007968  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962  0.007962  0.007962  \n",
       "\n",
       "[5 rows x 1170 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.to_csv('ninekrecords.csv', header = False, index= False) # saving it as a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp['patient'] = patient_label_list # updating the df with the labels.\n",
    "temp['activity'] = activity_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "          7         8         9    ...         1162      1163      1164  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1165      1166      1167      1168      1169  patient  activity  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966       p1       a01  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960       p1       a01  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966       p1       a01  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968       p1       a01  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962       p1       a01  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp.to_csv('ninekrecordswlabels.csv', header = False, index= False) # saving with the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully saved the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going ahead with PCA now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp.drop(['patient', 'activity'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1160</th>\n",
       "      <th>1161</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "       7         8         9       ...         1160      1161      1162  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1163      1164      1165      1166      1167      1168      1169  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960  0.007960  0.007960  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  0.007966  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968  0.007968  0.007968  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962  0.007962  0.007962  \n",
       "\n",
       "[5 rows x 1170 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im gonna try with `PCA` to see whether 9120x1170 fairs better or 9120x30, yes I'm going to reduce 1170 features into 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X = actual.as_matrix()\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X)\n",
    "X_dash = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.55855639e-01,   2.50681716e-05,   4.18788360e-04, ...,\n",
       "         -1.56821266e-04,  -2.13399660e-04,  -5.53551064e-04],\n",
       "       [ -5.56309979e-01,   2.82745468e-05,   4.18077173e-04, ...,\n",
       "         -1.03343276e-04,  -1.72688514e-04,  -4.90035550e-04],\n",
       "       [ -5.55609418e-01,   1.79540654e-05,   4.19014734e-04, ...,\n",
       "         -5.78772252e-05,  -4.11797203e-04,  -6.16432059e-04],\n",
       "       ..., \n",
       "       [  5.44632267e-01,  -8.36528542e-02,  -7.06172225e-02, ...,\n",
       "          2.58918466e-03,   4.61738342e-03,  -3.68394173e-03],\n",
       "       [  9.44554381e-01,   4.37055906e-04,  -1.28225558e-02, ...,\n",
       "         -4.00693495e-03,   6.12902191e-03,  -1.36532122e-02],\n",
       "       [  1.98146480e+00,   3.82718952e-03,   3.52893969e-02, ...,\n",
       "          1.08709486e-02,  -8.98053803e-03,  -5.71206037e-03]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dash # the reduced matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(X_dash) # passing the array into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.555856</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>...</td>\n",
       "      <td>9.791382e-05</td>\n",
       "      <td>-0.000164</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.556310</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>...</td>\n",
       "      <td>3.022188e-05</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.555609</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.478823e-05</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>-0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.555990</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>...</td>\n",
       "      <td>4.157959e-05</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555658</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>...</td>\n",
       "      <td>2.772035e-07</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.555856  0.000025  0.000419  0.000038 -0.000716 -0.000726  0.001239   \n",
       "1 -0.556310  0.000028  0.000418  0.000036 -0.000713 -0.000724  0.001234   \n",
       "2 -0.555609  0.000018  0.000419  0.000021 -0.000703 -0.000718  0.001231   \n",
       "3 -0.555990  0.000029  0.000417  0.000039 -0.000715 -0.000728  0.001247   \n",
       "4 -0.555658  0.000019  0.000425  0.000024 -0.000701 -0.000714  0.001223   \n",
       "\n",
       "         7         8         9     ...               20        21        22  \\\n",
       "0 -0.000194  0.002798  0.012813    ...     9.791382e-05 -0.000164  0.001206   \n",
       "1 -0.000199  0.002731  0.012509    ...     3.022188e-05 -0.000034  0.001149   \n",
       "2 -0.000156  0.002711  0.012504    ...    -9.478823e-05  0.000144  0.000851   \n",
       "3 -0.000215  0.002794  0.012732    ...     4.157959e-05 -0.000068  0.001167   \n",
       "4 -0.000171  0.002714  0.012477    ...     2.772035e-07  0.000019  0.001020   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0  0.000655  0.000001 -0.000071 -0.000121 -0.000157 -0.000213 -0.000554  \n",
       "1  0.000652 -0.000043 -0.000076 -0.000117 -0.000103 -0.000173 -0.000490  \n",
       "2  0.000605 -0.000239 -0.000013 -0.000219 -0.000058 -0.000412 -0.000616  \n",
       "3  0.000664 -0.000019 -0.000037 -0.000138 -0.000130 -0.000105 -0.000490  \n",
       "4  0.000639 -0.000154 -0.000130 -0.000097 -0.000048 -0.000214 -0.000560  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9120, 30)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally converted it into 9120 x 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df['patient'] = patient_label_list  # setting the labels along with the reduced df\n",
    "new_df['activity'] = activity_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.555856</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.012813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000213</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.556310</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.000173</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.555609</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000219</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.555990</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.012732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555658</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>-0.000154</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000048</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000560</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.555856  0.000025  0.000419  0.000038 -0.000716 -0.000726  0.001239   \n",
       "1 -0.556310  0.000028  0.000418  0.000036 -0.000713 -0.000724  0.001234   \n",
       "2 -0.555609  0.000018  0.000419  0.000021 -0.000703 -0.000718  0.001231   \n",
       "3 -0.555990  0.000029  0.000417  0.000039 -0.000715 -0.000728  0.001247   \n",
       "4 -0.555658  0.000019  0.000425  0.000024 -0.000701 -0.000714  0.001223   \n",
       "\n",
       "          7         8         9    ...           22        23        24  \\\n",
       "0 -0.000194  0.002798  0.012813    ...     0.001206  0.000655  0.000001   \n",
       "1 -0.000199  0.002731  0.012509    ...     0.001149  0.000652 -0.000043   \n",
       "2 -0.000156  0.002711  0.012504    ...     0.000851  0.000605 -0.000239   \n",
       "3 -0.000215  0.002794  0.012732    ...     0.001167  0.000664 -0.000019   \n",
       "4 -0.000171  0.002714  0.012477    ...     0.001020  0.000639 -0.000154   \n",
       "\n",
       "         25        26        27        28        29  patient  activity  \n",
       "0 -0.000071 -0.000121 -0.000157 -0.000213 -0.000554       p1       a01  \n",
       "1 -0.000076 -0.000117 -0.000103 -0.000173 -0.000490       p1       a01  \n",
       "2 -0.000013 -0.000219 -0.000058 -0.000412 -0.000616       p1       a01  \n",
       "3 -0.000037 -0.000138 -0.000130 -0.000105 -0.000490       p1       a01  \n",
       "4 -0.000130 -0.000097 -0.000048 -0.000214 -0.000560       p1       a01  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/media/greed/Windows8_OS/Me/Files/Projects/ML and DS/Daily_sports_and_activities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv('pcafilewlabels.csv', header = False, index= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole preprocessing is done. Next moving onto prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of activity without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the necessary libraries and adding the labels to the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual['patient'] = patient_label_list\n",
    "actual['activity'] = activity_label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step below does LabelEncoding,  which is converting all string categories ('a1', 'a2',.. and 'p1', 'p2'...) into numerical categories [0, 1, 2 .. 18] for `activity` , since `scikit-learn` understands numbers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X2 = actual.iloc[:,1170:1172]\n",
    "X2 = X2.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "          7         8         9    ...         1162      1163      1164  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1165      1166      1167      1168      1169  patient  activity  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966       p1       a01  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960       p1       a01  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966       p1       a01  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968       p1       a01  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962       p1       a01  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p1</td>\n",
       "      <td>a01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient activity\n",
       "0      p1      a01\n",
       "1      p1      a01\n",
       "2      p1      a01\n",
       "3      p1      a01\n",
       "4      p1      a01"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = actual.iloc[:,1170:1172]\n",
    "X2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actual.drop(['patient', 'activity'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the LabelEncoded df , X2 with actual and storing it in X_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "          7         8         9    ...         1162      1163      1164  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1165      1166      1167      1168      1169  patient  activity  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960        0         0  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968        0         0  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962        0         0  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = actual.join(X2)\n",
    "X_t.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes the first 1170 columns, and sends it to `X`, and takes the series `X_t['activity']` and sends it to `y`, later with the help of `train_test_split` from `sklearn` the dataset is separated into `X_train, X_test, y_train, y_test` with training set containing 75% of the data, and testing set containing 25% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_t.iloc[:,0:1170]\n",
    "y = X_t['activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6840, 1170), (2280, 1170), (6840,), (2280,))"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_range = range(1, 30)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fc43e125b38>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngkRERGpFQSIiIrWiIBERkVr5PzNH0qQSWvdhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc44fa7ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for plotting the graph inside the notebook itself\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Values of K')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the dataset with several models. For top 5 models go [here](http://localhost:8888/notebooks/csir_cdri_test.ipynb#Better-models.-(-%3E-85%-accuracy-)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumb models. (< 85% accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 . Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.265350877193\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel = 'linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.319736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714912280702\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(penalty='l1', tol = 0.001)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. k Nearest Neighbors ( k = 3 )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.831140350877\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Neural Nets. With 'Adam' optimizer and ReLU activation, with one hidden layer of 100 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.848684210526\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter = 500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(max_iter = 450)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better models. ( > 85% accuracy )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this kind of data, ensemble techniques seem to be the best, we can see that below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Decision Tree Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.855263157895\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. ExtraTrees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.887280701754\n"
     ]
    }
   ],
   "source": [
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901754385965\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.910087719298\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936877076412\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Patient without passing the activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "          7         8         9    ...         1162      1163      1164  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1165      1166      1167      1168      1169  patient  activity  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960        0         0  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968        0         0  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962        0         0  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_t.iloc[:, 0:1170]\n",
    "y = X_t['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.640789473684\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71798245614\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.757456140351\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796929824561\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824122807018\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the bonus task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Patient with activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1162</th>\n",
       "      <th>1163</th>\n",
       "      <th>1164</th>\n",
       "      <th>1165</th>\n",
       "      <th>1166</th>\n",
       "      <th>1167</th>\n",
       "      <th>1168</th>\n",
       "      <th>1169</th>\n",
       "      <th>patient</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014742</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014671</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.007265</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0.007960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014821</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>0.012470</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.007903</td>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.008430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0.007966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014823</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.007951</td>\n",
       "      <td>0.007274</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014680</td>\n",
       "      <td>0.008905</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.008413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.014742  0.009023  0.012503  0.007937  0.007945  0.007945  0.007273   \n",
       "1  0.014671  0.008831  0.012605  0.007926  0.007890  0.007933  0.007265   \n",
       "2  0.014821  0.008891  0.012470  0.007938  0.007930  0.007946  0.007272   \n",
       "3  0.014823  0.008911  0.012706  0.007943  0.007937  0.007951  0.007274   \n",
       "4  0.014680  0.008905  0.012661  0.007929  0.007932  0.007930  0.007267   \n",
       "\n",
       "          7         8         9    ...         1162      1163      1164  \\\n",
       "0  0.007898  0.008066  0.008259    ...     0.007966  0.007966  0.007966   \n",
       "1  0.007898  0.008056  0.008472    ...     0.007960  0.007960  0.007960   \n",
       "2  0.007903  0.008075  0.008430    ...     0.007966  0.007966  0.007966   \n",
       "3  0.007905  0.008077  0.008436    ...     0.007968  0.007968  0.007968   \n",
       "4  0.007895  0.008066  0.008413    ...     0.007962  0.007962  0.007962   \n",
       "\n",
       "       1165      1166      1167      1168      1169  patient  activity  \n",
       "0  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "1  0.007960  0.007960  0.007960  0.007960  0.007960        0         0  \n",
       "2  0.007966  0.007966  0.007966  0.007966  0.007966        0         0  \n",
       "3  0.007968  0.007968  0.007968  0.007968  0.007968        0         0  \n",
       "4  0.007962  0.007962  0.007962  0.007962  0.007962        0         0  \n",
       "\n",
       "[5 rows x 1172 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_t.iloc[:, 0:1170].join(X_t['activity'])\n",
    "y = X_t['patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 451)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.657894736842\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors = 3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.739473684211\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.762719298246\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792105263158\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.824561403509\n"
     ]
    }
   ],
   "source": [
    "model = BaggingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Please go check the PCA ipynb, then proceed downwards, I did them parallely thus two ipynbs **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Dataset, 9120 x 1172"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Activity with signals.\n",
    "\n",
    "\n",
    "|**Model**                    |**Accuracy**|\n",
    "|-----------------------------|------------|\n",
    "|Gradient Boosting Classifier | 0.9368 |\n",
    "|Bagging Classifier|0.9100|\n",
    "|Random Forest Classifier|0.9017|\n",
    "|ExtraTrees Classifier|0.8872|\n",
    "|Decision Tree|0.8552|\n",
    "\n",
    "*Runner up*: Neural Networks (DNN) : 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Patient with signals and activity, The bonus task.\n",
    "\n",
    "\n",
    "|**Model**                    |**Accuracy**|\n",
    "|-----------------------------|------------|\n",
    "|Bagging Classifier|0.8245|\n",
    "|Gradient Boosting Classifier | 0.7921 |\n",
    "|Random Forest Classifier|0.7627|\n",
    "|Decision Tree|0.7394|\n",
    "|kNN (k=3) |0.6578|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also Predicting Patient with signals alone, also has been performed, and the results can be seen by scrolling up, they are almost on par with the above results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA reduced Dataset, 9120 x 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Activity with signals.\n",
    "\n",
    "\n",
    "|**Model**                    |**Accuracy**|\n",
    "|-----------------------------|------------|\n",
    "|ExtraTrees Classifier|0.8767|\n",
    "|Gradient Boosting Classifier | 0.8745 |\n",
    "|Random Forest Classifier|0.8596|\n",
    "\n",
    "\n",
    "*Runner up*: Bagging Classifier : 0.8320, Neural Networks (DNN) : 0.8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|**Model**                    |**Accuracy**|\n",
    "|-----------------------------|------------|\n",
    "|MLP with Adam + ReLU |0.8065|\n",
    "|MLP with Adam + Sigmoid | 0.7771 |\n",
    "\n",
    "MLP with SGD are worse than I expected, they converged within 1000 epochs, with accuracy < 40%, whereas Adam optmizers made it possible with less than 500 epochs and accuracy > 75%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Patient with activity also has been done, but the results are far from comparable to the results from the actual dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
